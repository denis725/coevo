% THIS VERSION CONTAINS LATIN HYPERCUBE SAMPLING

clear all

tic

wb=waitbar(0,'progress');

    % P A R A M E T E R S

iterations=1;    %how often the simulation is repeated
gen=2000;              %number of simulated generations
w0=10;              %base fitness
pA0=1/2;            %initial success rate of option A
pB0=1/2;            %initial success rate of option B
nindi=1000;        %total population
param=22;           %number of parameters per individual
q=.9;               %discount rate for older memory
b=1;                %benefit from choosing correctly
mutationrate=0;     %the rate at which traits mutate
mutationincr=0;     %the factor by which the probability is modified
nstrat=10;          %number of strategies
lambda=1;           %sensitiviy factor for reinforcement learners
kdoubt=2;           %threshold value for use of maj. tal. by IDCs
compare_self=0;     % Usually, ITW only screens others and then adopts the
                    % choice of the best of them. However, they could
                    % include themselves in the sample, so that they don't
                    % switch if they are best themselves. To introduce this
                    % effect, set compare_self=1; else =0.

% % latin hypercube sampling
% 'random seed'
% rand('seed',17413)

% vectors to choose from
% all starts from uniform distribution
uniform   = [0.1:0.1:1];

% parameters are transformed:
tmaxVec   = round(exp(uniform*5.5));
regimeVec = exp(uniform*2)-1;
incrVec   = exp(uniform/20)-1;
pincrVec  = [0.1:0.1:1];
dpVec     = uniform/2 - 0.275;
tallyVec  = uniform*10 + 1;
pskillVec = (uniform - 0.1)/3;

% form latin hypercube (#num params, #num tests, minimize correlation, #num
% trials to form hypercube)
numParams = 7;
numTests  = 20;
lh = lhsdesign(numParams, numTests, 'criterion', 'correlation', 'iterations', 1000);
[lhSorted, lhInt] = sort(lh); % get the order as integers

for numT = 1:numTests
    
    waitbar(numT/(1+numTests),wb);

    tmax = tmaxVec(numT);
    regime = regimeVec(numT);
    incr = incrVec(numT);
    pincr = pincrVec(numT);
    dpA = dpVec(numT);
    dpB = dpVec(numT);
    tallyn = tallyVec(numT);
    pskill = pskillVec(numT);
    
    pA0=pA0+dpA;pB0=pB0+dpB;


    % STRATEGIES:
    % each individual agent is characterized by the following parameters:
    %   1) history of past choices (A->1, B->0)
    %   2) history of past successes (1->success, 0->failure)
    %   3) the fitness
    %   4) NON-FUNCTIONAL the sample size
    %   5) NON-FUNCTIONAL memory (for probabilistic reinforcement learning)
    %   6) bias towards choosing A (for non-probabilistic reinforcement learning)
    %   7) whom ITW tracks
    %   8) recentness of information of ITW (age in periods)
    %   9) individual differences in skill
    %  10) which strategy is chosen this round (important for mixed strategies)
    %  11) whether in this period, the individual has chosen the better of the
    %      two options (yes->1, no->0, draw->0.5)
    %  12) whenever an individual is imitated by ITW, isource gets +1
    %  --- an individual has a certain probability to use each strategy
    %      usually, each individual has only one strategy that she uses
    %      each round, but mixed strategies are possible. In that case
    %      the following parameters determine the probabilities. In case
    %      of pure strategies, the probability for one strategy is 1 and
    %      for the rest 0.
    % EXPLANATION: For the population tensor, the dimensions are:
    %   1) individuals
    %   2) parameters (choice, success...)
    %   3) time
    % INDICES
    % for convenience, these indices are not passed to the coevo function.
    % Changes here have thus to be updated in coevo as well
    ichoice=1;isucc=2;ifit=3;itally=4;imemo=5;ibias=6;
    itrack=7;irecent=8;iskill=9;istrat=10;ibest=11;isource=12;
    % STRATS:
    ipind=13;   % 1  individual learner (threshold reinforcement learning)
    ipcon=14;   % 2  conformist, sample size 3
    ipoil=15;   % 3  opportunistic individual learners, sample size 3
    ipoc =16;   % 4  opportunistic conformists, sample size 3
    ipidc=17;   % 5  in doubt, conform, sample size 3
    ipitw=18;   % 6  imitate the wealthiest, sample size 7
    ip4m1=19;   % 7  scoring-type PBSL weights [4/-1], sample size 7
    ip10 =20;   % 8  scoring-type PBSL weights [1/0], sample size 3
    ipMcE=21;   % 9  PBSLs McElreath, sample size 3
    ippct=22;   % 10 PBSLs payoff-conformist trade-off, sample size 6


    % I N I T I A L I Z A T I O N
    ninitial=zeros(nindi,param);        %the initial state of the population
    nt=zeros(nindi,param*gen/10);          %tensor for just every 10th final state of the population
    perfmat=zeros(nstrat,gen/10);
%     ntn=zeros(nindi,param);             %nt now

    pfix=zeros(2,tmax);               %fixed environment, for testing purposes only

    % INITIAL POPULATION
    ninitial(:,ichoice)=rand(nindi,1)>1/2;                %initialize random choice in 1st round
    ninitial(:,iskill)=(-.5+rand(nindi,1))*pskill;        %skill is uniformly distributed with mean 0

    % ~~~~~~~~~~~~ change initial population here~~~~~~~~~~~~~~~
    % use this procedure to define the initial population for
    % pure strategies
    ind=[...
        900;          % INDividual learners
        0;          % CONformists
        0;          % Opportunstic Individual Learners
        0;          % Opportunstic Conformists
        0;          % In Doubt, Conform
        100;          % Imitate The Wealthiest
        0;          % PBSLs [4/-1]
        0;          % PBSLs [1/0]
        0;          % PBSLs McElreath
        0];         % PBSLs Payoff-Conformism Trade-off
    

    s = 0;
    j = 1;
    k = 0;
    for numStrats = 1:nstrat
      s = s+1;
      k = k+ind(numStrats);
      ninitial(j:k, istrat) = s;
      j = j + ind(numStrats);
    end
    
    unik = unique(ninitial(:, istrat));

    % check whether there are only pure strategies
    % if yes -> genetics = 0
    % if not -> genetics = 1
    % as soon as mutations are possible, genetics are not pure
    genetics=coevo_check_genetics2(...
        mutationrate,nstrat,ninitial,ipind,nindi,gen);


    % S T A R T   O F   T H E   S I M U L A T I O N

    for g=1:gen

        % initialize simulation
        [n,pA,pB] = coevo51(...
                            tmax,...    %tmax time of simulation
                            nindi,...   %nindi # of individuals
                            nstrat,...  %# of strategy types
                            tallyn,...  %sample size itw
                            incr,...    %the increment
                            pincr,...   %probability that patch quality changes
                            w0,...      %the base fitness
                            b,...       %the benefit from succeeding
                            ninitial,...%initial state of the population
                            pA0,...     %remember last pA
                            pB0,...     %remember last pB
                            dpA,...     %change in mean pA
                            dpB,...     %change in mean pB
                            pfix,...    %a fixed environment for testing purposes
                            param,...   %# of parameter values
                            q,...       %oblivousness, discount for older memory
                            lambda,... plo %sensitivity factor for reinforcement learners, higher->steeper
                            genetics,...%whether pure (0) or mixed strategies (1)
                            kdoubt,...  %threshold value for IDCs
                            compare_self,...    %ITW looks at own wealth?
                            regime);    %regime, how the environment changes. 1->low variance, 2->high variance

        choicesvec=n(:,ichoice,tmax);   %remember as 1st choice for stats

        % I N H E R I T A N C E
        ninitial2=ninitial;                 %copy initial state
        ntnow = nt(:,:,g);                  %current final state
        nt(:,:,g)=n(:,:,tmax);              %the final state

        % COPY INHERITABLE CHARACTERS + MUTATE
        ninitial=coevo_next_gen5(nindi,g,param,ntnow,mutationrate,...
            nstrat,ichoice,ifit,itally,istrat,iskill,ipind,mutationincr);

        % remember LAST STATE OF ENVIRONMENT
        pA0=pA(1,tmax);
        pB0=pB(1,tmax);

        % distribute skill anew
        ninitial(:,ichoice)=choicesvec;
        % distribute skill anew
        ninitial(:,iskill)=(-.5+rand(nindi,1))*pskill;

    end

    % E N D   O F   S I M U L A T I O N
    
    fig1 = zeros(length(unik), gen);
    for s = 1:length(unik)
        fig1(s, :) = squeeze(sum(nt(:, istrat, :) == unik(s)));
    end
    
    % save, using a random name
    fileName = strcat('data/evo_', num2str(numT), '.mat' );
    save(fileName, 'fig1')
    
    paramsName = strcat('data/evo_', num2str(numT), 'params_.mat' );
    save(paramsName, 'tmax', 'regime', 'incr', 'pincr', 'dpA', 'dpB', 'tallyn', 'pskill')

end

close(wb) %close waitbar

toc
